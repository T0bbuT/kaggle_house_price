{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "from scipy import stats\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "df_train = pd.read_csv(\"../data/input/train.csv\")\n",
    "df_train_Id = df_train[\"Id\"]\n",
    "df_train = df_train.drop(\"Id\", axis=1)\n",
    "\n",
    "df_test = pd.read_csv(\"../data/input/test.csv\")\n",
    "df_test_Id = df_test[\"Id\"]\n",
    "df_test = df_test.drop(\"Id\", axis=1)\n",
    "\n",
    "df_all_data = pd.concat([df_train, df_test])\n",
    "\n",
    "print(f\"{df_train.shape=}\")\n",
    "display(df_train.head(5))\n",
    "print(f\"{df_test.shape=}\")\n",
    "display(df_test.head(5))\n",
    "\n",
    "print(\"-\" * 10, \"df_train.info()\", \"-\" * 10)\n",
    "print(df_train.info())\n",
    "print(\"\\n\", \"-\" * 10, \"df_test.info()\", \"-\" * 10)\n",
    "print(df_test.info())\n",
    "\n",
    "# # ydata_profilingを使う場合。時間かかるので注意\n",
    "# # minimal=Falseにすると更に時間がかかり、出力されるhtmlも非常に重くなるなので注意\n",
    "\n",
    "# if not os.path.exists(\"ydata_profiling\"):\n",
    "#     os.makedirs(\"ydata_profiling\")\n",
    "\n",
    "# profile = ProfileReport(df_all_data, minimal=True)\n",
    "# profile_path = \"ydata_profiling/kaggle_houseprices_minimal.html\"\n",
    "# profile.to_file(profile_path)\n",
    "\n",
    "# print(f\"{profile_path}にレポートが出力されました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SalePrice = df_train[\"SalePrice\"]\n",
    "\n",
    "skewness_SalePrice = SalePrice.skew()\n",
    "kurtosis_SalePrice = SalePrice.kurtosis()\n",
    "\n",
    "print(\"-\" * 10, 'df_train[\"SalePrice\"].describe()', \"-\" * 10)\n",
    "print(df_train[\"SalePrice\"].describe())\n",
    "\n",
    "print(f\"{skewness_SalePrice=}\")\n",
    "print(f\"{kurtosis_SalePrice=}\")\n",
    "\n",
    "# plotlyではkdeを描写するのが面倒なのでseabornで描写\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.histplot(SalePrice, stat=\"density\", kde=True, ax=ax[0])\n",
    "ax[0].set_title(\"ヒストグラムと正規分布(黒線)\")\n",
    "ax[0].tick_params(axis=\"x\", labelsize=8, rotation=20)\n",
    "\n",
    "xmin, xmax = ax[0].get_xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y_norm = stats.norm.pdf(x, np.mean(SalePrice), np.std(SalePrice))\n",
    "ax[0].plot(x, y_norm, \"k\", linewidth=1)\n",
    "\n",
    "stats.probplot(SalePrice, plot=ax[1])\n",
    "ax[1].set_title(\"正規確率プロット\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data_features = df_all_data.drop([\"SalePrice\"], axis=1)\n",
    "numeric_features = df_all_data_features.select_dtypes(include=\"number\").columns\n",
    "\n",
    "\n",
    "df_skew_kurt = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": numeric_features,\n",
    "        \"Skewness\": [\n",
    "            stats.skew(df_all_data_features[col], nan_policy=\"omit\")\n",
    "            for col in numeric_features\n",
    "        ],\n",
    "        \"Kurtosis\": [\n",
    "            stats.kurtosis(df_all_data_features[col], nan_policy=\"omit\")\n",
    "            for col in numeric_features\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "display(df_skew_kurt.sort_values(by=\"Skewness\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_train.corr(numeric_only=True)\n",
    "\"\"\"\n",
    "    訓練データdf_trainの相関係数行列\n",
    "    corr_matrix = df_train.corr(numeric_only=True)\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    abs(corr_matrix), cmap=\"viridis\", annot=True, fmt=\".1f\", annot_kws={\"fontsize\": 6}\n",
    ")\n",
    "\n",
    "plt.suptitle(\"訓練データの相関係数(絶対値)行列_カテゴリ変数を除く\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly版。インデックス番号が一目で確認できる\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "\n",
    "threshold = 0.6\n",
    "high_corr_cols = (\n",
    "    corr_matrix[\"SalePrice\"][abs(corr_matrix[\"SalePrice\"]) >= threshold]\n",
    "    .sort_values(ascending=False)\n",
    "    .index\n",
    ").drop(\"SalePrice\")\n",
    "\n",
    "# プロットのサイズを指定\n",
    "plot_size = len(high_corr_cols)\n",
    "rows = plot_size // 3 + 1  # 行数\n",
    "cols = 3  # 列数\n",
    "\n",
    "# サブプロットの作成\n",
    "fig = sp.make_subplots(\n",
    "    rows=rows,\n",
    "    cols=cols,\n",
    "    subplot_titles=[\n",
    "        f\"{col} vs SalePrice （相関係数{corr_matrix['SalePrice'][col]:.3f}）\"\n",
    "        for col in high_corr_cols\n",
    "    ],\n",
    "    horizontal_spacing=0.05,\n",
    "    vertical_spacing=0.1,\n",
    ")\n",
    "\n",
    "# high_corr_colsにある特徴量ごとに散布図を描く\n",
    "for i, col in enumerate(high_corr_cols):\n",
    "    row = i // cols + 1\n",
    "    col_num = i % cols + 1\n",
    "    scatter = px.scatter(\n",
    "        df_train, x=col, y=\"SalePrice\", opacity=0.3, hover_data=[df_train.index]\n",
    "    )\n",
    "    for trace in scatter.data:\n",
    "        fig.add_trace(trace, row=row, col=col_num)\n",
    "    fig.update_annotations()\n",
    "\n",
    "# グラフのタイトルを設定\n",
    "fig.update_layout(\n",
    "    title_text=f\"SalePriceとの相関係数の絶対値が{threshold}以上の特徴量についての散布図\",\n",
    "    showlegend=False,\n",
    "    height=400 * rows,\n",
    "    width=1200,\n",
    ")\n",
    "\n",
    "# グラフの表示\n",
    "fig.show()\n",
    "\n",
    "# レイアウト調節 https://data-analytics.fun/2021/06/19/plotly-subplots/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 外れ値処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外れ値処理(訓練データ)\n",
    "# 外れ値のインデックス番号は、plotlyで描いたグラフから得た\n",
    "df_train_befdrop = df_train\n",
    "df_train = df_train.drop(df_train.index[[523, 1298]])\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_train, x=\"GrLivArea\", y=\"SalePrice\", opacity=0.3, hover_data=[df_train.index]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"SalePrice vs GrLivArea. 外れ値処理後\",\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=600,\n",
    ")\n",
    "\n",
    "# グラフの表示\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 欠損値補完・列削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値処理(訓練データ、テストデータ)\n",
    "df_all_data = pd.concat([df_train, df_test])\n",
    "\n",
    "df_missing_values_count = df_all_data.isna().sum()\n",
    "df_missing_values_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Missing_count\": df_missing_values_count,\n",
    "        \"Percent (%)\": round(df_missing_values_count / len(df_all_data) * 100, 2),\n",
    "    }\n",
    ").sort_values(\"Missing_count\", ascending=False)\n",
    "\n",
    "# chatGPTに作ってもらった各特徴量の説明をまとめたcsvを読み込み、欠損値に関する表と結合\n",
    "df_data_description = pd.read_csv(\n",
    "    \"../junk/データ説明/data_descripsion_simple_jp.csv\", index_col=0\n",
    ")\n",
    "df_missing_value_description = pd.concat(\n",
    "    [df_missing_values_table, df_data_description], axis=1\n",
    ")\n",
    "\n",
    "# csvに出力。これとydata_profilingのレポートを眺めながら各欠損値をどう処理するか考える。\n",
    "if not os.path.exists(\"../junk/欠損値処理\"):\n",
    "    os.makedirs(\"../junk/欠損値処理\")\n",
    "df_missing_value_description.to_csv(\n",
    "    \"../junk/欠損値処理/missing_value_processing.csv\", encoding=\"utf-8_sig\"\n",
    ")\n",
    "\n",
    "display(df_missing_value_description.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotFrontageの欠損割合が多いが、何で補完するかが難しい。どれかのカテゴリ変数に対する傾向がないか調べてみる\n",
    "\n",
    "# object型のデータが入っている列を抽出\n",
    "object_cols = df_all_data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# プロットのサイズを指定\n",
    "plot_size = len(object_cols)\n",
    "rows = plot_size // 6 + 1  # 行数\n",
    "cols = 6  # 列数\n",
    "\n",
    "# サブプロットの作成\n",
    "fig = sp.make_subplots(\n",
    "    rows=rows,\n",
    "    cols=cols,\n",
    "    subplot_titles=[f\"{col} vs LotFrontage\" for col in object_cols],\n",
    ")\n",
    "\n",
    "# object_colsにある特徴量ごとに箱ひげ図を描く\n",
    "for i, col in enumerate(object_cols):\n",
    "    row = i // cols + 1\n",
    "    col_num = i % cols + 1\n",
    "    box = px.box(df_all_data, x=col, y=\"LotFrontage\")\n",
    "    for trace in box.data:\n",
    "        fig.add_trace(trace, row=row, col=col_num)\n",
    "    fig.update_annotations()\n",
    "\n",
    "# グラフのタイトルを設定\n",
    "fig.update_layout(\n",
    "    title_text=f\"各カテゴリ変数に対するLotFrontageの箱ひげ図\",\n",
    "    showlegend=False,\n",
    "    height=400 * rows,\n",
    "    width=1600,\n",
    ")\n",
    "\n",
    "# グラフの表示\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=\"Neighborhood\", y=\"LotFrontage\"が傾向を捉えていそう。詳しく確認する\n",
    "\n",
    "fig = px.box(df_all_data, x=\"Neighborhood\", y=\"LotFrontage\")\n",
    "\n",
    "fig.update_layout(\n",
    "    # title_text=\" \",\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=1000,\n",
    ")\n",
    "\n",
    "# グラフの表示\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各地域\"Neighborhood\"の\"LotFrontage\"の中央値で欠損値を補完する\n",
    "\n",
    "df_medLot_groupby_Neighborhood = df_all_data.groupby(by=\"Neighborhood\")[\n",
    "    \"LotFrontage\"\n",
    "].agg(\"median\")\n",
    "\n",
    "\n",
    "def fillnaLot(row):\n",
    "    \"\"\"\n",
    "    ある1つの住宅データについて、\"LotFrontage\"列の値が欠損している場合はそのデータの地域（\"Neighborhood\"）の\"LotFrontage\"の中央値を返す。\n",
    "    欠損していない場合、元の値をそのまま返す。\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): \"LotFrontage\"列の欠損値処理をしたいデータ\n",
    "\n",
    "    Return\n",
    "    -------\n",
    "        \"LotFrontage\"列が…\n",
    "            欠損の場合: df_group_LotFrontage[row[\"Neighborhood\"]]\n",
    "            欠損でない場合: row[\"LotFrontage\"]\n",
    "    \"\"\"\n",
    "    if pd.isna(row[\"LotFrontage\"]):\n",
    "        return df_medLot_groupby_Neighborhood[row[\"Neighborhood\"]]\n",
    "    else:\n",
    "        return row[\"LotFrontage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotFrontageの補完\n",
    "df_all_data[\"LotFrontage\"] = df_all_data.apply(fillnaLot, axis=1)\n",
    "\n",
    "# \"None\"で補完\n",
    "cols_fillNone = [\n",
    "    \"MiscFeature\",\n",
    "    \"Alley\",\n",
    "    \"Fence\",\n",
    "    \"MasVnrType\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageFinish\",\n",
    "    \"GarageQual\",\n",
    "    \"GarageCond\",\n",
    "    \"GarageType\",\n",
    "    \"BsmtCond\",\n",
    "    \"BsmtExposure\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtFinType2\",\n",
    "    \"BsmtFinType1\",\n",
    "]\n",
    "# 0で補完\n",
    "cols_fill0 = [\n",
    "    \"GarageYrBlt\",\n",
    "    \"MasVnrArea\",\n",
    "    \"BsmtHalfBath\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"GarageArea\",\n",
    "    \"GarageCars\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"BsmtFinSF2\",\n",
    "    \"BsmtUnfSF\",\n",
    "    \"TotalBsmtSF\",\n",
    "]\n",
    "# 最頻値で補完\n",
    "cols_fillmode = [\n",
    "    \"MSZoning\",\n",
    "    \"Functional\",\n",
    "    \"Exterior2nd\",\n",
    "    \"Exterior1st\",\n",
    "    \"SaleType\",\n",
    "    \"KitchenQual\",\n",
    "    \"Electrical\",\n",
    "]\n",
    "# 列削除：PoolQC(99.7%が欠損)、Utilities(99.6%が\"allpub\")、PoolArea(99.6%が0)\n",
    "cols_drop = [\"PoolQC\", \"Utilities\", \"PoolArea\"]\n",
    "\n",
    "for col in cols_fillNone:\n",
    "    df_all_data[col] = df_all_data[col].fillna(\"None\")\n",
    "for col in cols_fill0:\n",
    "    df_all_data[col] = df_all_data[col].fillna(0)\n",
    "for col in cols_fillmode:\n",
    "    df_all_data[col] = df_all_data[col].fillna(df_all_data[col].mode()[0])\n",
    "df_all_data = df_all_data.drop(columns=cols_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新たな特徴量の作成(訓練データ、テストデータ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しい特徴量の作成\n",
    "# 'YrBltAndRemod': 'YearBuilt' + 'YearRemodAdd'\n",
    "\n",
    "df_all_data[\"TotalSF\"] = (\n",
    "    df_all_data[\"TotalBsmtSF\"] + df_all_data[\"1stFlrSF\"] + df_all_data[\"2ndFlrSF\"]\n",
    ")\n",
    "df_all_data[\"TotalFinSF\"] = (\n",
    "    df_all_data[\"BsmtFinSF1\"]\n",
    "    + df_all_data[\"BsmtFinSF2\"]\n",
    "    + df_all_data[\"1stFlrSF\"]\n",
    "    + df_all_data[\"2ndFlrSF\"]\n",
    ")\n",
    "df_all_data[\"TotalBathrooms\"] = (\n",
    "    df_all_data[\"BsmtFullBath\"]\n",
    "    + 0.5 * df_all_data[\"BsmtHalfBath\"]\n",
    "    + df_all_data[\"FullBath\"]\n",
    "    + 0.5 * df_all_data[\"HalfBath\"]\n",
    ")\n",
    "df_all_data[\"TotalPorchSF\"] = (\n",
    "    df_all_data[\"3SsnPorch\"]\n",
    "    + df_all_data[\"EnclosedPorch\"]\n",
    "    + df_all_data[\"OpenPorchSF\"]\n",
    "    + df_all_data[\"ScreenPorch\"]\n",
    ")\n",
    "\n",
    "df_all_data[\"has2ndfloor\"] = df_all_data[\"2ndFlrSF\"] > 0\n",
    "df_all_data[\"hasGarage\"] = df_all_data[\"GarageArea\"] > 0\n",
    "df_all_data[\"hasBsmt\"] = df_all_data[\"TotalBsmtSF\"] > 0\n",
    "df_all_data[\"hasFireplace\"] = df_all_data[\"Fireplaces\"] > 0\n",
    "\n",
    "df_all_data[\n",
    "    [\n",
    "        \"TotalSF\",\n",
    "        \"TotalFinSF\",\n",
    "        \"TotalBathrooms\",\n",
    "        \"TotalPorchSF\",\n",
    "        \"has2ndfloor\",\n",
    "        \"hasGarage\",\n",
    "        \"hasBsmt\",\n",
    "        \"hasFireplace\",\n",
    "    ]\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カテゴリ変数のエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from lightgbm import LGBMRegressor, plot_tree\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "# 1. カテゴリごとのユニークな値を取得\n",
    "category_mappings = {\n",
    "    col: set(df_all_data[col].dropna().unique())\n",
    "    for col in df_all_data.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "}\n",
    "\n",
    "# 2. 同じカテゴリーリストを持つ変数をグループ化\n",
    "from collections import defaultdict\n",
    "\n",
    "grouped_categories = defaultdict(list)\n",
    "for col, categories in category_mappings.items():\n",
    "    grouped_categories[frozenset(categories)].append(col)\n",
    "\n",
    "# 結果の表示\n",
    "for categories, columns in grouped_categories.items():\n",
    "    print(\"カテゴリーリスト:\", categories)\n",
    "    print(\"同じマッピングを持つ変数:\", columns)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換前\n",
    "display(df_all_data.head(5))\n",
    "\n",
    "# 順序を定義する\n",
    "mapping = {\n",
    "    \"ExterQual\": [\"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"KitchenQual\": [\"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"ExterCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\"],\n",
    "    \"HeatingQC\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"BsmtQual\": [\"None\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"BsmtCond\": [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\"],\n",
    "    \"FireplaceQu\": [\"None\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"GarageQual\": [\"None\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"GarageCond\": [\"None\", \"Po\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"BsmtExposure\": [\"None\", \"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"BsmtFinType1\": [\"None\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"BsmtFinType2\": [\"None\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"GarageFinish\": [\"None\", \"Unf\", \"RFn\", \"Fin\"],\n",
    "}\n",
    "\n",
    "# 各変数を順序付きでエンコード\n",
    "for col, order in mapping.items():\n",
    "    df_all_data[col] = df_all_data[col].astype(\n",
    "        pd.CategoricalDtype(categories=order, ordered=True)\n",
    "    )\n",
    "\n",
    "# Ordinal encodingに変換\n",
    "df_all_data = df_all_data.apply(\n",
    "    lambda x: x.cat.codes if x.dtype.name == \"category\" else x\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "display(df_all_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残りのカテゴリ変数をone-hot encodingする\n",
    "\n",
    "# object型のデータが入っている列を抽出\n",
    "object_cols = df_all_data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# one-hot encoding\n",
    "df_all_data = pd.get_dummies(df_all_data).reset_index(drop=True)\n",
    "\n",
    "display(df_all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数値変換(目的変数、特徴量)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数SalePriceの数値変換(box-cox)\n",
    "\n",
    "# まず、ここまで使ってきたdf_all_dataをdf_trainとdf_testに分割し直す\n",
    "ntrain = len(df_train)\n",
    "\n",
    "df_train = df_all_data[:ntrain]\n",
    "df_test = df_all_data[ntrain:].drop([\"SalePrice\"], axis=1)\n",
    "\n",
    "# 全データ、訓練データを特徴量と目的変数に分ける\n",
    "df_all_data_features = df_all_data.drop([\"SalePrice\"], axis=1)\n",
    "df_train_features = df_train.drop([\"SalePrice\"], axis=1)\n",
    "SalePrice = df_train[\"SalePrice\"]\n",
    "\n",
    "print(\"boxcox前\")\n",
    "print(f\"{stats.skew(SalePrice)=}\")\n",
    "print(f\"{stats.kurtosis(SalePrice)=}\")\n",
    "\n",
    "# SalePriceに対してBox-Cox変換の実行\n",
    "SalePrice_boxcox, lambda_SalePrice_boxcox = stats.boxcox(SalePrice)\n",
    "\n",
    "# 変換後のSalePriceを新しいDataFrameに保存し、元のインデックスを保持\n",
    "df_SalePrice_boxcox = pd.DataFrame(\n",
    "    SalePrice_boxcox, index=SalePrice.index, columns=[\"SalePrice_boxcox\"]\n",
    ")\n",
    "\n",
    "print(\"boxcox後\")\n",
    "print(f\"{stats.skew(SalePrice_boxcox)=}\")\n",
    "print(f\"{stats.kurtosis(SalePrice_boxcox)=}\")\n",
    "print(\"Lambda value used for transformation:\", lambda_SalePrice_boxcox)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "fig.suptitle(\"SalePriceの様子_boxcox後\")\n",
    "\n",
    "sns.histplot(SalePrice_boxcox, stat=\"density\", kde=True, ax=ax[0])\n",
    "ax[0].set_title(\"ヒストグラムと正規分布(黒線)\")\n",
    "ax[0].tick_params(axis=\"x\", labelsize=8, rotation=20)\n",
    "\n",
    "xmin, xmax = ax[0].get_xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y_norm = stats.norm.pdf(x, np.mean(SalePrice_boxcox), np.std(SalePrice_boxcox))\n",
    "ax[0].plot(x, y_norm, \"k\", linewidth=1)\n",
    "\n",
    "stats.probplot(SalePrice_boxcox, plot=ax[1])\n",
    "ax[1].set_title(\"正規確率プロット\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の数値変換(yeo-johnson)\n",
    "\n",
    "# 特徴量の数値変換は、bool型を除いた数値型の特徴量についてのみ行う\n",
    "numeric_features = df_all_data_features.select_dtypes(include=\"number\").columns\n",
    "\n",
    "skewness = df_all_data_features[numeric_features].skew()\n",
    "high_skew_features = skewness[skewness > 0.75].index\n",
    "\n",
    "# yeo-johnson変換器を作成。学習\n",
    "pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "pt.fit(df_all_data_features[high_skew_features])\n",
    "# 訓練データにyeo-johnson変換を実行\n",
    "df_train_features[high_skew_features] = pt.transform(\n",
    "    df_train_features[high_skew_features]\n",
    ")\n",
    "# テストデータにyeo-johnson変換を実行\n",
    "df_test[high_skew_features] = pt.transform(df_test[high_skew_features])\n",
    "\n",
    "# 訓練データにboxcoxしたSalePriceを結合\n",
    "df_train = pd.concat([df_train_features, df_SalePrice_boxcox], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "\n",
    "# データの準備\n",
    "X = df_train.drop([\"SalePrice_boxcox\"], axis=1)\n",
    "y = df_train[\"SalePrice_boxcox\"]\n",
    "\n",
    "# クロスバリデーション\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "def objective(trial, model_name):\n",
    "    scores = []\n",
    "\n",
    "    # モデルごとのパラメータ範囲を設定\n",
    "    if model_name == \"LGBMRegressor\":\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\n",
    "                \"learning_rate\", 1e-4, 0.1, log=True\n",
    "            ),  # 対数スケールで探索\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),  # 連続範囲で探索\n",
    "        }\n",
    "        model = LGBMRegressor(**params, verbose=-1)\n",
    "    elif model_name == \"Ridge\":\n",
    "        params = {\n",
    "            \"alpha\": trial.suggest_float(\n",
    "                \"alpha\", 1e-3, 100.0, log=True\n",
    "            )  # 対数スケールで探索\n",
    "        }\n",
    "        model = Ridge(**params)\n",
    "    elif model_name == \"Lasso\":\n",
    "        params = {\n",
    "            \"alpha\": trial.suggest_float(\n",
    "                \"alpha\", 1e-5, 1.0, log=True\n",
    "            )  # 対数スケールで探索\n",
    "        }\n",
    "        model = Lasso(**params, max_iter=100000)\n",
    "\n",
    "    # クロスバリデーションで評価\n",
    "    for fold_idx, (tr_idx, va_idx) in enumerate(kf.split(X)):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_va)\n",
    "\n",
    "        # 負の値を回避\n",
    "        y_pred = np.maximum(y_pred, 1e-6)\n",
    "\n",
    "        # 逆Box-Cox変換\n",
    "        y_pred_inv_boxcox = special.inv_boxcox(y_pred, lambda_SalePrice_boxcox)\n",
    "        y_va_inv_boxcox = special.inv_boxcox(y_va, lambda_SalePrice_boxcox)\n",
    "\n",
    "        # 評価スコアをRMSEで計算\n",
    "        score = rmse(np.log(y_pred_inv_boxcox), np.log(y_va_inv_boxcox))\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# 各モデルの最適パラメータを保存する辞書\n",
    "best_params_dict = {}\n",
    "\n",
    "# モデルごとにOptunaでパラメータチューニング\n",
    "for model_name in [\"LGBMRegressor\", \"Ridge\", \"Lasso\"]:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_name), n_trials=50)\n",
    "\n",
    "    # 最適パラメータとスコアを表示\n",
    "    print(f\"\\n{model_name}の最適パラメータ: {study.best_params}\")\n",
    "    print(f\"最良スコア: {study.best_value}\\n\")\n",
    "\n",
    "    # 最適パラメータを辞書に保存\n",
    "    best_params_dict[model_name] = study.best_params\n",
    "\n",
    "# 各モデルの最適パラメータが辞書に保存されていることを確認\n",
    "print(\"各モデルの最適パラメータ一覧:\")\n",
    "for model_name, params in best_params_dict.items():\n",
    "    print(f\"{model_name}: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPEの計算関数\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "# 最良パラメータを使ってMAPEを計算\n",
    "for model_name, best_params in best_params_dict.items():\n",
    "    if model_name == \"LGBMRegressor\":\n",
    "        model = LGBMRegressor(**best_params, verbose=-1)\n",
    "    elif model_name == \"Ridge\":\n",
    "        model = Ridge(**best_params)\n",
    "    elif model_name == \"Lasso\":\n",
    "        model = Lasso(**best_params, max_iter=100000)\n",
    "\n",
    "    # クロスバリデーションでMAPEを計算\n",
    "    mape_scores = []\n",
    "    for fold_idx, (tr_idx, va_idx) in enumerate(kf.split(X)):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_va)\n",
    "\n",
    "        # 負の値を回避\n",
    "        y_pred = np.maximum(y_pred, 1e-6)\n",
    "\n",
    "        # 逆Box-Cox変換\n",
    "        y_pred_inv_boxcox = special.inv_boxcox(y_pred, lambda_SalePrice_boxcox)\n",
    "        y_va_inv_boxcox = special.inv_boxcox(y_va, lambda_SalePrice_boxcox)\n",
    "\n",
    "        # MAPEを計算\n",
    "        mape = mean_absolute_percentage_error(y_va_inv_boxcox, y_pred_inv_boxcox)\n",
    "        mape_scores.append(mape)\n",
    "\n",
    "    # 平均MAPEを表示\n",
    "    print(f\"{model_name}の平均MAPE: {np.mean(mape_scores):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(\"train_test_submission\"):\n",
    "#     os.makedirs(\"train_test_submission\")\n",
    "\n",
    "# for model_name in [\"LGBMRegressor\", \"Ridge\", \"Lasso\"]:\n",
    "#     params = best_params_dict[model_name]\n",
    "#     model = None\n",
    "\n",
    "#     if model_name == \"LGBMRegressor\":\n",
    "#         model = LGBMRegressor(**params, verbose=-1)\n",
    "#     elif model_name == \"Ridge\":\n",
    "#         model = Ridge(**params)\n",
    "#     elif model_name == \"Lasso\":\n",
    "#         model = Lasso(**params)\n",
    "\n",
    "#     # 学習・予測\n",
    "#     model.fit(X, y)\n",
    "#     pred = model.predict(df_test)\n",
    "#     sub_pred = special.inv_boxcox(pred, lambda_SalePrice_boxcox)\n",
    "#     sub_pred = np.maximum(sub_pred, 1e-6)\n",
    "\n",
    "#     # 提出データ作成\n",
    "#     submission = pd.DataFrame({\"Id\": df_test_Id, \"SalePrice\": sub_pred})\n",
    "#     submission_path = f\"train_test_submission/submission_{model_name}.csv\"\n",
    "#     submission.to_csv(submission_path, index=False)\n",
    "#     print(f\"{model_name}の提出データが{submission_path}に出力されました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_kaggle_house_price",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
